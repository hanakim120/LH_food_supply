{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "import fasttext\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_data(corpus, iter=10, seed=0):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    \n",
    "    for _ in range(iter):\n",
    "        for i in range(corpus.shape[0]):\n",
    "            string = np.array(corpus[i].split())\n",
    "            indices = np.random.permutation(len(string))\n",
    "            new_string = np.array([' '.join(string[indices])])\n",
    "            corpus = np.c_.concatenate([corpus, new_string])\n",
    "    return np.array(list(set(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(text='embedding',\n",
    "             DIM=2,\n",
    "             epoch=1000,\n",
    "             use_pca=0,\n",
    "             use_tok=False,\n",
    "             sum_reduction=False,\n",
    "             sep_date=True,\n",
    "             use_corpus=True,\n",
    "             min_count=5,\n",
    "             window_size=3,\n",
    "             min_ngram=2,\n",
    "             max_ngram=4,\n",
    "             dummy_corpus=True,\n",
    "             corpus_iter=10,\n",
    "             ):\n",
    "    train_df = pd.read_csv('train.csv', encoding='utf-8')\n",
    "    test_df = pd.read_csv('test.csv', encoding='utf-8')\n",
    "    y = train_df[['중식계', '석식계']]\n",
    "    sample = pd.read_csv('sample_submission.csv', encoding='utf-8')\n",
    "\n",
    "    # crawling\n",
    "    temp = pd.read_csv('temp.csv', encoding='utf-8')\n",
    "\n",
    "    TRAIN_LENGTH = 1205\n",
    "\n",
    "    train_df.drop(columns=['중식계', '석식계'], inplace=True)\n",
    "\n",
    "    df = pd.concat([train_df, test_df], axis=0)\n",
    "    df = pd.merge(df, temp, on='일자')\n",
    "\n",
    "    if sep_date :\n",
    "        df['month'] = df.일자.apply(lambda x : int(x[-5 :-3]))\n",
    "        df['day'] = df.일자.apply(lambda x : int(x[-2 :]))\n",
    "        df['week'] = df.day.apply(lambda x : x // 7)\n",
    "\n",
    "        df.drop(columns=['일자', 'day'], inplace=True)\n",
    "    else :\n",
    "        df.일자 = pd.to_datetime(df.일자)\n",
    "\n",
    "    columns = ['조식메뉴', '중식메뉴', '석식메뉴']\n",
    "    for col in columns :\n",
    "        df[col] = df[col].str.replace('/', ' ')\n",
    "        df[col] = df[col].str.replace(r'[(]{1}[ㄱ-힣:,.A-Za-z]*[)]{1}', '')\n",
    "        df[col] = df[col].str.replace(r'[ ]{2, }', ' ')\n",
    "        df[col] = df[col].str.replace('*', ' ')\n",
    "        df[col] = df[col].apply(lambda x : x.strip())\n",
    "\n",
    "    if text == 'embedding' :\n",
    "        breakfast = df.조식메뉴.values\n",
    "        launch = df.중식메뉴.values\n",
    "        dinner = df.석식메뉴.values\n",
    "\n",
    "        embedding_features = []\n",
    "\n",
    "        if use_corpus:\n",
    "            corpus = np.concatenate([breakfast, launch, dinner], axis=0)\n",
    "            if dummy_corpus:\n",
    "                corpus = dummy_data(corpus, iter=corpus_iter)\n",
    "            with open('./data/corpus.txt', 'w', -1, encoding='utf-8') as f:\n",
    "                f.write('\\n'.join(corpus))\n",
    "            model = fasttext.train_unsupervised('./data/corpus.txt',\n",
    "                                                dim=DIM,\n",
    "                                                ws=window_size,\n",
    "                                                epoch=epoch,\n",
    "                                                min_count=min_count,\n",
    "                                                minn=min_ngram,\n",
    "                                                maxn=max_ngram,\n",
    "                                                )\n",
    "\n",
    "            breakfast_array = np.zeros((1255, DIM))\n",
    "            launch_array = np.zeros((1255, DIM))\n",
    "            dinner_array = np.zeros((1255, DIM))\n",
    "\n",
    "            for i in range(1255) :\n",
    "                breakfast_array[i] = model.get_sentence_vector(breakfast[i]) / len(breakfast[i].split())\n",
    "                launch_array[i] = model.get_sentence_vector(launch[i]) / len(launch[i].split())\n",
    "                dinner_array[i] = model.get_sentence_vector(dinner[i]) / len(dinner[i].split())\n",
    "\n",
    "            for i in range(DIM) :\n",
    "                embedding_features.append('breakfast_{}'.format(i))\n",
    "                embedding_features.append('launch_{}'.format(i))\n",
    "                embedding_features.append('dinner_{}'.format(i))\n",
    "\n",
    "            tmp = pd.concat([\n",
    "                pd.DataFrame(breakfast_array, columns=['breakfast_{}'.format(i) for i in range(DIM)]),\n",
    "                pd.DataFrame(launch_array, columns=['launch_{}'.format(i) for i in range(DIM)]),\n",
    "                pd.DataFrame(dinner_array, columns=['dinner_{}'.format(i) for i in range(DIM)])], axis=1)\n",
    "\n",
    "        else:\n",
    "            menus = [breakfast, launch, dinner]\n",
    "\n",
    "            models = []\n",
    "            for i, n in enumerate(['breakfast', 'launch', 'dinner']) :\n",
    "                with open('./data/{}.txt'.format(n), 'w', -1, encoding='utf-8') as f :\n",
    "                    f.write('\\n'.join(menus[i][:TRAIN_LENGTH]))\n",
    "                if use_tok :\n",
    "                    models.append(fasttext.train_unsupervised('./data/{}.tok.txt'.format(n),\n",
    "                                                              dim=DIM,\n",
    "                                                              ws=window_size,\n",
    "                                                              epoch=epoch,\n",
    "                                                              min_count=min_count,\n",
    "                                                              minn=min_ngram,\n",
    "                                                              maxn=max_ngram,\n",
    "                                                              ))\n",
    "                else :\n",
    "                    models.append(fasttext.train_unsupervised('./data/{}.txt'.format(n),\n",
    "                                                              dim=DIM,\n",
    "                                                              ws=window_size,\n",
    "                                                              epoch=epoch,\n",
    "                                                              min_count=min_count,\n",
    "                                                              minn=min_ngram,\n",
    "                                                              maxn=max_ngram,\n",
    "                                                              ))\n",
    "\n",
    "            embedding_features = []\n",
    "\n",
    "            if sum_reduction :\n",
    "                breakfast_array = np.zeros((1255, 1))\n",
    "                launch_array = np.zeros((1255, 1))\n",
    "                dinner_array = np.zeros((1255, 1))\n",
    "\n",
    "                for i in range(1255) :\n",
    "                    breakfast_array[i] = [sum(models[0].get_sentence_vector(breakfast[i]))]\n",
    "                    launch_array[i] = [sum(models[1].get_sentence_vector(launch[i]))]\n",
    "                    dinner_array[i] = [sum(models[2].get_sentence_vector(dinner[i]))]\n",
    "\n",
    "                tmp = pd.concat([\n",
    "                    pd.DataFrame(breakfast_array, columns=['breakfast']),\n",
    "                    pd.DataFrame(launch_array, columns=['launch']),\n",
    "                    pd.DataFrame(dinner_array, columns=['dinner'])], axis=1)\n",
    "\n",
    "                ms = MinMaxScaler()\n",
    "                ms.fit(tmp.breakfast[:TRAIN_LENGTH].values.reshape(-1, 1))\n",
    "                tmp.breakfast = ms.transform(tmp.breakfast.values.reshape(-1, 1))\n",
    "                ms.fit(tmp.launch[:TRAIN_LENGTH].values.reshape(-1, 1))\n",
    "                tmp.launch = ms.transform(tmp.launch.values.reshape(-1, 1))\n",
    "                ms.fit(tmp.dinner[:TRAIN_LENGTH].values.reshape(-1, 1))\n",
    "                tmp.dinner = ms.transform(tmp.dinner.values.reshape(-1, 1))\n",
    "\n",
    "            else :\n",
    "                breakfast_array = np.zeros((1255, DIM))\n",
    "                launch_array = np.zeros((1255, DIM))\n",
    "                dinner_array = np.zeros((1255, DIM))\n",
    "\n",
    "                for i in range(1255) :\n",
    "                    breakfast_array[i] = models[0].get_sentence_vector(breakfast[i]) / len(breakfast[i].split())\n",
    "                    launch_array[i] = models[1].get_sentence_vector(launch[i]) / len(launch[i].split())\n",
    "                    dinner_array[i] = models[2].get_sentence_vector(dinner[i]) / len(dinner[i].split())\n",
    "\n",
    "                for i in range(DIM) :\n",
    "                    embedding_features.append('breakfast_{}'.format(i))\n",
    "                    embedding_features.append('launch_{}'.format(i))\n",
    "                    embedding_features.append('dinner_{}'.format(i))\n",
    "\n",
    "                tmp = pd.concat([\n",
    "                    pd.DataFrame(breakfast_array, columns=['breakfast_{}'.format(i) for i in range(DIM)]),\n",
    "                    pd.DataFrame(launch_array, columns=['launch_{}'.format(i) for i in range(DIM)]),\n",
    "                    pd.DataFrame(dinner_array, columns=['dinner_{}'.format(i) for i in range(DIM)])], axis=1)\n",
    "\n",
    "    if text == 'tokenize' :\n",
    "        from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "        from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "        from sklearn.decomposition import PCA\n",
    "\n",
    "        menus = ['조식메뉴', '중식메뉴', '석식메뉴']\n",
    "        for col in menus :\n",
    "            tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "            tokenizer.fit_on_texts(df[col][:TRAIN_LENGTH])\n",
    "            seq = tokenizer.texts_to_sequences(df[col])\n",
    "            pad = pad_sequences(seq)\n",
    "\n",
    "            if use_pca > 0 :\n",
    "                pca = PCA(n_components=use_pca)\n",
    "                pca.fit(pad[:TRAIN_LENGTH])\n",
    "                pad = pca.transform(pad)\n",
    "\n",
    "            length = len(pad[0])\n",
    "            pad = pd.DataFrame(pad, columns=['{}_{}'.format(col, i) for i in range(length)])\n",
    "            df = pd.concat([df.reset_index(drop=True), pd.DataFrame(pad)], axis=1)\n",
    "        df.drop(columns=menus, inplace=True)\n",
    "\n",
    "    # Normalize\n",
    "    scaling_cols = ['본사정원수', '본사휴가자수', '본사출장자수',\n",
    "                    '본사시간외근무명령서승인건수', '현본사소속재택근무자수']\n",
    "    for col in scaling_cols :\n",
    "        ms = MinMaxScaler()\n",
    "        ms.fit(df[col][:TRAIN_LENGTH].values.reshape(-1, 1))\n",
    "        df[col] = ms.transform(df[col].values.reshape(-1, 1))\n",
    "\n",
    "    if text == 'embedding' :\n",
    "        new_df = pd.concat([df.reset_index(drop=True), tmp.reset_index(drop=True)], axis=1)\n",
    "        new_df.drop(columns=['조식메뉴', '중식메뉴', '석식메뉴'], inplace=True)\n",
    "    else :\n",
    "        new_df = df.reset_index(drop=True)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    le.fit(new_df.요일.values[:TRAIN_LENGTH])\n",
    "    new_df.요일 = le.transform(new_df.요일.values)\n",
    "\n",
    "    train_df = new_df[:TRAIN_LENGTH]\n",
    "    # train_df, valid_df, train_y, valid_y = train_test_split(df, train_y, test_size=0.2, random_state=0)\n",
    "    test_df = new_df[TRAIN_LENGTH :]\n",
    "    \n",
    "    return train_df, test_df, y, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       쌀밥/잡곡밥 (쌀,현미흑미:국내산) 육개장  자반고등어구이  두부조림  건파래무침 ...\n",
       "1       콩나물밥*양념장 (쌀,현미흑미:국내산) 어묵국  유산슬 (쇠고기:호주산) 아삭고추무...\n",
       "2       쌀밥/잡곡밥 (쌀,현미흑미:국내산) 청국장찌개  황태양념구이 (황태:러시아산) 고기...\n",
       "3       미니김밥*겨자장 (쌀,현미흑미:국내산) 우동  멕시칸샐러드  군고구마  무피클  포...\n",
       "4       쌀밥/잡곡밥 (쌀,현미흑미:국내산) 차돌박이찌개 (쇠고기:호주산) 닭갈비 (닭고기:...\n",
       "                              ...                        \n",
       "1200       김치볶음밥 미니쫄우동*맛살튀김 브로콜리깨소스무침 계란후라이 고들빼기무침 겉절이김치 \n",
       "1201              흑미밥 쇠고기무국 삼치양념구이 비엔나채소볶음 숙주나물당근무침 포기김치 \n",
       "1202          흑미밥 수제비국 수제맛쵸킹탕수육 유부채소겨자냉채 참나물무침 갓김치/겉절이김치 \n",
       "1203              흑미밥 열무된장국 장어강정*데리야끼소스 깻잎쌈*생강채 오이선 포기김치 \n",
       "1204           (New)할라피뇨멸치주먹밥 잔치국수 수제고기육전 쑥갓나물 양파초절임 깍두기 \n",
       "Name: 석식메뉴, Length: 1205, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.석식메뉴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoding(train_df, test_df, TARGET=1, verbose=2):\n",
    "    TRAIN_LENGTH = 1205\n",
    "    \n",
    "    df = pd.concat([train_df, test_df], axis=0)\n",
    "    text_df = df[['조식메뉴', '중식메뉴', '석식메뉴']]\n",
    "\n",
    "    mecab = Mecab(dicpath='C:/mecab/mecab-ko-dic')\n",
    "\n",
    "    for i in range(len(text_df.조식메뉴)):\n",
    "        text_df.조식메뉴[i] = ','.join(text_df.조식메뉴[i].split())\n",
    "        text_df.조식메뉴[i] = ' '.join(mecab.morphs(text_df.조식메뉴[i]))\n",
    "    for i in range(len(text_df.중식메뉴)):\n",
    "        text_df.중식메뉴[i] = ','.join(text_df.중식메뉴[i].split())\n",
    "        text_df.중식메뉴[i] = ' '.join(mecab.morphs(text_df.중식메뉴[i]))\n",
    "    for i in range(len(text_df.석식메뉴)):\n",
    "        text_df.석식메뉴[i] = ','.join(text_df.석식메뉴[i].split())\n",
    "        text_df.석식메뉴[i] = ' '.join(mecab.morphs(text_df.석식메뉴[i]))\n",
    "\n",
    "    vect = CountVectorizer()\n",
    "    vect.fit(text_df['조식메뉴'].values[:TRAIN_LENGTH])\n",
    "    breakfast = vect.transform(text_df['조식메뉴'].values).toarray()\n",
    "    vect.fit(text_df['중식메뉴'].values[:TRAIN_LENGTH])\n",
    "    launch = vect.transform(text_df['중식메뉴'].values).toarray()\n",
    "    vect.fit(text_df['석식메뉴'].values[:TRAIN_LENGTH])\n",
    "    dinner = vect.transform(text_df['석식메뉴'].values).toarray()\n",
    "\n",
    "    class Encoder(tf.keras.models.Model):\n",
    "        def __init__(self, step, input_size):\n",
    "            super(Encoder, self).__init__()\n",
    "            self.model = tf.keras.models.Sequential([\n",
    "                InputLayer(input_shape=(input_size,)),\n",
    "                Dense(input_size - step * 1, activation='relu'),\n",
    "                Dense(input_size - step * 2, activation='relu'),\n",
    "                Dense(input_size - step * 3, activation='relu'),\n",
    "                Dense(input_size - step * 4, activation='relu'),\n",
    "                Dense(input_size - step * 5),\n",
    "            ])\n",
    "\n",
    "        def call(self, x):\n",
    "            z = self.model(x)\n",
    "            return z\n",
    "\n",
    "    class Decoder(tf.keras.models.Model):\n",
    "        def __init__(self, step, input_size, output_size):\n",
    "            super(Decoder, self).__init__()\n",
    "            self.model = tf.keras.models.Sequential([\n",
    "                InputLayer(input_shape=(input_size,)),\n",
    "                Dense(output_size - step * 4, activation='relu'),\n",
    "    #             Dense(output_size - step * 3, activation='relu'),\n",
    "                Dense(output_size - step * 2, activation='relu'),\n",
    "    #             Dense(output_size - step * 1, activation='relu'),\n",
    "                Dense(output_size),\n",
    "            ])\n",
    "        def call(self, x):\n",
    "            z = self.model(x)\n",
    "            return z\n",
    "\n",
    "    class AutoEncoder(tf.keras.models.Model):\n",
    "        def __init__(self, input_size, step):\n",
    "            super(AutoEncoder, self).__init__()\n",
    "            self.encoder = Encoder(step, input_size)\n",
    "            self.decoder = Decoder(step, input_size - step * 5, input_size)\n",
    "\n",
    "        def call(self, x):\n",
    "            y = self.encoder(x)\n",
    "            z = self.decoder(y)\n",
    "            return z\n",
    "\n",
    "    enc_df = pd.DataFrame()\n",
    "\n",
    "    i = 1\n",
    "    for menu in [breakfast, launch, dinner]:\n",
    "        print('+' * 10, 'Train {}'.format(i), '+' * 10)\n",
    "        train_X, valid_X = train_test_split(menu[:TRAIN_LENGTH], \n",
    "                                            test_size=0.1, \n",
    "                                            shuffle=True, \n",
    "                                            random_state=0)\n",
    "\n",
    "        STEP = (menu.shape[1] - TARGET) // 5\n",
    "        INPUT = menu.shape[1]\n",
    "\n",
    "        model = AutoEncoder(INPUT, STEP)\n",
    "        model.compile(loss='mse', optimizer='adam', metrics='mse')\n",
    "        model.fit(train_X, train_X,\n",
    "                  validation_data=(valid_X, valid_X),\n",
    "                  epochs=1000, \n",
    "                  callbacks=tf.keras.callbacks.EarlyStopping(patience=10),\n",
    "                  verbose=verbose)\n",
    "        result = model.encoder(menu)\n",
    "        result = np.array(result)\n",
    "\n",
    "        enc_df = pd.concat([enc_df, pd.DataFrame(result)], axis=1)\n",
    "        i += 1\n",
    "        print()\n",
    "\n",
    "    train_df.drop(columns=['조식메뉴', '중식메뉴', '석식메뉴'], inplace=True)\n",
    "    test_df.drop(columns=['조식메뉴', '중식메뉴', '석식메뉴'], inplace=True)\n",
    "\n",
    "    train_df_enc = pd.concat([train_df, enc_df[:TRAIN_LENGTH]], axis=1)\n",
    "    test_df_enc = pd.concat([test_df, enc_df[TRAIN_LENGTH:]], axis=1)\n",
    "    \n",
    "    column_names = list(train_df_enc.columns[:8]) + [i for i in range(enc_df.shape[1])]\n",
    "    train_df_enc.columns = column_names\n",
    "    test_df_enc.columns = column_names\n",
    "\n",
    "    return train_df_enc, test_df_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(text='embedding', \n",
    "               DIM=3, \n",
    "               sep_date=False, \n",
    "               verbose=2,\n",
    "               min_count=5,\n",
    "               window_size=3,\n",
    "               min_ngram=2,\n",
    "               max_ngram=4,\n",
    "               sum_reduction=False,\n",
    "               use_tok=False,\n",
    "               dummy_corpus=True,\n",
    "               corpus_iter=10,\n",
    "              ): \n",
    "    if text == 'autoencode':\n",
    "        train_df, test_df, y, sample = get_data(text='raw', \n",
    "                                                sep_date=sep_date,\n",
    "                                               )\n",
    "        train_df_enc, test_df_enc = autoencoding(train_df, test_df, TARGET=DIM)\n",
    "        \n",
    "        return train_df_enc, test_df_enc, y, sample\n",
    "    else:\n",
    "        train_df, test_df, y, sample = get_data(text=text, \n",
    "                                                DIM=DIM, \n",
    "                                                sep_date=sep_date,\n",
    "                                                use_tok=use_tok,\n",
    "                                                min_count=min_count,\n",
    "                                                window_size=window_size,\n",
    "                                                min_ngram=min_ngram,\n",
    "                                                max_ngram=max_ngram,\n",
    "                                                sum_reduction=sum_reduction,\n",
    "                                                dummy_corpus=dummy_corpus,\n",
    "                                                corpus_iter=corpus_iter\n",
    "                                               )\n",
    "        \n",
    "        return train_df, test_df, y, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_catboost(train_df, test_df, depth=2, lr=0.3, verbose=100, k=0, test_size=0.2, seed=0):\n",
    "    if  train_df.columns[8] == 'month':\n",
    "        cat_features = [0, 8, 9]\n",
    "    else:\n",
    "        cat_features = []\n",
    "        \n",
    "    print('Categorical Features :', cat_features)\n",
    "    \n",
    "    if k > 0:\n",
    "        skf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "        folds = []\n",
    "        for train_idx, valid_idx in skf.split(train_df, y.중식계) :\n",
    "            folds.append((train_idx, valid_idx))\n",
    "\n",
    "        random.seed(42)\n",
    "        models_launch = {}\n",
    "        models_dinner = {}\n",
    "        scores_launch = []\n",
    "        scores_dinner = []\n",
    "        for fold in range(k) :\n",
    "            print(f'===================================={fold + 1}============================================')\n",
    "            train_idx, valid_idx = folds[fold]\n",
    "            train_X, valid_X, train_y, valid_y = train_df.iloc[train_idx], train_df.iloc[valid_idx],\\\n",
    "                                                 y.중식계[train_idx], y.중식계[valid_idx]\n",
    "\n",
    "            train_pool_launch = Pool(train_X, train_y, cat_features=cat_features)\n",
    "            valid_pool_launch = Pool(valid_X, valid_y, cat_features=cat_features)\n",
    "            reg_launch = CatBoostRegressor(\n",
    "                                       loss_function='MAE', \n",
    "                                       has_time=True,\n",
    "                                       eval_metric='MAE',\n",
    "                                       iterations=3000,\n",
    "                                       depth=depth,\n",
    "                                       rsm=0.9,\n",
    "                                       random_seed=0,\n",
    "                                       boost_from_average=True,\n",
    "                                       reg_lambda=20.0,)\n",
    "            reg_launch.fit(train_pool_launch, \n",
    "                    eval_set=valid_pool_launch, \n",
    "                    use_best_model=True, \n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose=verbose)\n",
    "\n",
    "            models_launch[fold] = reg_launch\n",
    "            y_pred_launch = reg_launch.predict(valid_X)\n",
    "            mae_launch = mean_absolute_error(y_pred_launch, valid_y)\n",
    "            scores_launch.append(mae_launch)\n",
    "\n",
    "            train_y, valid_y = y.석식계[train_idx], y.석식계[valid_idx]\n",
    "            train_pool_dinner = Pool(train_X, train_y, cat_features=cat_features)\n",
    "            valid_pool_dinner = Pool(valid_X, valid_y, cat_features=cat_features)\n",
    "            reg_dinner = CatBoostRegressor(\n",
    "                                       loss_function='MAE', \n",
    "                                       has_time=True,\n",
    "                                       eval_metric='MAE',\n",
    "                                       iterations=3000,\n",
    "                                       depth=depth,\n",
    "                                       rsm=0.9,\n",
    "                                       boost_from_average=True,\n",
    "                                       random_seed=0,\n",
    "                                       reg_lambda=20.0,)\n",
    "            reg_dinner.fit(train_pool_dinner, \n",
    "                    eval_set=valid_pool_dinner, \n",
    "                    use_best_model=True, \n",
    "                    early_stopping_rounds=100, \n",
    "                    verbose=verbose)\n",
    "\n",
    "            models_dinner[fold] = reg_dinner\n",
    "            y_pred_dinner = reg_dinner.predict(valid_X)\n",
    "            mae_dinner = mean_absolute_error(y_pred_dinner, valid_y)\n",
    "            scores_dinner.append(mae_dinner)\n",
    "            print(f'================================================================================\\n\\n')\n",
    "\n",
    "        print('-' * 50, 'Result', '-' * 50, '\\n')\n",
    "        print('Mean launch : {}'.format(np.mean(scores_launch, axis=0)))\n",
    "        print('Mean dinner : {}'.format(np.mean(scores_dinner, axis=0)))\n",
    "        print('Total : {}'.format((np.mean(scores_launch, axis=0) + np.mean(scores_dinner, axis=0)) / 2))\n",
    "        print('_' * 106)\n",
    "        \n",
    "        return models_launch, models_dinner \n",
    "    \n",
    "    else:\n",
    "        train_X, valid_X, train_y, valid_y = train_test_split(train_df, \n",
    "                                                              y.중식계, \n",
    "                                                              test_size=test_size, \n",
    "                                                              random_state=seed)\n",
    "\n",
    "        train_pool_launch = Pool(train_X, train_y, cat_features=cat_features)\n",
    "        valid_pool_launch = Pool(valid_X, valid_y, cat_features=cat_features)\n",
    "\n",
    "        reg_launch = CatBoostRegressor(loss_function='MAE', \n",
    "                                       has_time=True,\n",
    "                                       eval_metric='MAE',\n",
    "                                       iterations=3000,\n",
    "                                       depth=depth,\n",
    "                                       rsm=0.9,\n",
    "                                       boost_from_average=True,\n",
    "                                       reg_lambda=20.0,\n",
    "                                       random_seed=0\n",
    "                                      )\n",
    "\n",
    "        reg_launch.fit(train_pool_launch, \n",
    "                eval_set=valid_pool_launch, \n",
    "                use_best_model=True, \n",
    "                early_stopping_rounds=100,\n",
    "                verbose=verbose)\n",
    "\n",
    "        y_pred_launch = reg_launch.predict(valid_X)\n",
    "        mae_launch = mean_absolute_error(y_pred_launch, valid_y)\n",
    "\n",
    "        # ===========================================================================================\n",
    "        train_X, valid_X, train_y, valid_y = train_test_split(train_df, \n",
    "                                                              y.석식계, \n",
    "                                                              test_size=test_size, \n",
    "                                                              random_state=seed)\n",
    "\n",
    "        train_pool_launch = Pool(train_X, train_y, cat_features=cat_features)\n",
    "        valid_pool_launch = Pool(valid_X, valid_y, cat_features=cat_features)\n",
    "\n",
    "        reg_dinner = CatBoostRegressor(loss_function='MAE', \n",
    "                                       has_time=True,\n",
    "                                       eval_metric='MAE',\n",
    "                                       iterations=3000,\n",
    "                                       depth=depth,\n",
    "                                       rsm=0.9,\n",
    "                                       boost_from_average=True,\n",
    "                                       reg_lambda=20.0,\n",
    "                                       random_seed=0\n",
    "                                      )\n",
    "\n",
    "        reg_dinner.fit(train_pool_launch, \n",
    "                eval_set=valid_pool_launch, \n",
    "                use_best_model=True, \n",
    "                early_stopping_rounds=100,\n",
    "                verbose=verbose)\n",
    "\n",
    "        y_pred_dinner = reg_dinner.predict(valid_X)\n",
    "        mae_dinner = mean_absolute_error(y_pred_dinner, valid_y)\n",
    "\n",
    "        print('MAE_LAUNCH :', mae_launch)\n",
    "        print('MAE_DINNER :', mae_dinner)\n",
    "        print('TOTAL SCORE :', (mae_launch + mae_dinner) / 2)\n",
    "    \n",
    "    return reg_launch, reg_dinner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(reg_launch, reg_dinner, sample, file_fn='new'):\n",
    "    if type(reg_launch) == 'list':\n",
    "        for i in range(10):\n",
    "            sample.중식계 += reg_launch[i].predict(test_df)\n",
    "            sample.석식계 += reg_dinner[i].predict(test_df)\n",
    "\n",
    "        sample.중식계 /= 10\n",
    "        sample.석식계 /= 10\n",
    "        sample.to_csv('submission_{}.csv'.format(file_fn), index=False)\n",
    "    else:\n",
    "        sample.중식계 = reg_launch.predict(test_df)\n",
    "        sample.석식계 = reg_dinner.predict(test_df)\n",
    "\n",
    "        sample.to_csv('submission_{}.csv'.format(file_fn), index=False)\n",
    "    print(sample.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features : [0, 8, 9, 10]\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "Invalid type for cat_feature[non-default value idx=0,feature_idx=10]=-0.08910762518644333 : cat_features must be integer or string, real number values and NaN values should be converted to string.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_cat_factor_bytes_representation\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_id_object_bytes_string_representation\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCatBoostError\u001b[0m: bad object for id: -0.08910762518644333",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-327-af862dbad977>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# test_df = test_df.iloc[:, :8]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m reg_launch, reg_dinner = train_catboost(train_df, \n\u001b[0m\u001b[0;32m     19\u001b[0m                                         \u001b[0mtest_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                                         \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-325-6bcafae2d598>\u001b[0m in \u001b[0;36mtrain_catboost\u001b[1;34m(train_df, test_df, depth, lr, verbose, k, test_size, seed)\u001b[0m\n\u001b[0;32m     86\u001b[0m                                                               random_state=seed)\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mtrain_pool_launch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mvalid_pool_launch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, cat_features, text_features, embedding_features, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[0;32m    586\u001b[0m                     )\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_init\u001b[1;34m(self, data, label, cat_features, text_features, embedding_features, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[0mbaseline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msamples_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_baseline_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_cat_factor_bytes_representation\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCatBoostError\u001b[0m: Invalid type for cat_feature[non-default value idx=0,feature_idx=10]=-0.08910762518644333 : cat_features must be integer or string, real number values and NaN values should be converted to string."
     ]
    }
   ],
   "source": [
    "# text = [embedding, tokenize, raw, autoencoding]\n",
    "train_df, test_df, y, sample = processing(text='embedding', \n",
    "                                          DIM=2,\n",
    "                                          verbose=0,\n",
    "                                          min_count=0,\n",
    "                                          window_size=3,\n",
    "                                          min_ngram=2,\n",
    "                                          max_ngram=3,   \n",
    "                                          sum_reduction=False,\n",
    "                                          use_tok=False,\n",
    "                                          sep_date=True,\n",
    "                                          dummy_corpus=True,\n",
    "                                          corpus_iter=2\n",
    "                                         )\n",
    "# train_df = train_df.iloc[:, :8]\n",
    "# test_df = test_df.iloc[:, :8]\n",
    "\n",
    "reg_launch, reg_dinner = train_catboost(train_df, \n",
    "                                        test_df,\n",
    "                                        depth=2, \n",
    "                                        verbose=100,\n",
    "                                        k=0, \n",
    "                                        test_size=0.2,\n",
    "                                        seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features : [0, 8, 9]\n",
      "0:\tlearn: 163.7071879\ttest: 168.2167625\tbest: 168.2167625 (0)\ttotal: 20.4ms\tremaining: 1m 1s\n",
      "100:\tlearn: 86.1392338\ttest: 87.8508187\tbest: 87.8508187 (100)\ttotal: 886ms\tremaining: 25.4s\n",
      "200:\tlearn: 76.0338330\ttest: 76.3176693\tbest: 76.3176693 (200)\ttotal: 1.83s\tremaining: 25.5s\n",
      "300:\tlearn: 71.0614750\ttest: 72.2836064\tbest: 72.2836064 (300)\ttotal: 2.9s\tremaining: 26s\n",
      "400:\tlearn: 68.3371029\ttest: 71.4206280\tbest: 71.4206280 (400)\ttotal: 3.7s\tremaining: 24s\n",
      "500:\tlearn: 66.1450491\ttest: 70.8753028\tbest: 70.8569770 (497)\ttotal: 4.45s\tremaining: 22.2s\n",
      "600:\tlearn: 64.4417721\ttest: 70.0613253\tbest: 70.0562338 (599)\ttotal: 5.2s\tremaining: 20.8s\n",
      "700:\tlearn: 62.8715975\ttest: 69.4688371\tbest: 69.4497303 (695)\ttotal: 5.92s\tremaining: 19.4s\n",
      "800:\tlearn: 61.5184769\ttest: 68.9559463\tbest: 68.9526442 (799)\ttotal: 6.66s\tremaining: 18.3s\n",
      "900:\tlearn: 60.2518474\ttest: 68.4964217\tbest: 68.4937468 (899)\ttotal: 7.46s\tremaining: 17.4s\n",
      "1000:\tlearn: 59.1131799\ttest: 68.0318036\tbest: 68.0318036 (1000)\ttotal: 8.15s\tremaining: 16.3s\n",
      "1100:\tlearn: 58.2654047\ttest: 67.7934124\tbest: 67.7872957 (1096)\ttotal: 8.86s\tremaining: 15.3s\n",
      "1200:\tlearn: 57.3650566\ttest: 67.5810116\tbest: 67.5790339 (1196)\ttotal: 9.62s\tremaining: 14.4s\n",
      "1300:\tlearn: 56.4967170\ttest: 67.3827569\tbest: 67.3765360 (1262)\ttotal: 10.4s\tremaining: 13.6s\n",
      "1400:\tlearn: 55.7870039\ttest: 67.1113146\tbest: 67.1113146 (1400)\ttotal: 11.2s\tremaining: 12.8s\n",
      "1500:\tlearn: 55.1478093\ttest: 66.8648342\tbest: 66.8648342 (1500)\ttotal: 12s\tremaining: 12s\n",
      "1600:\tlearn: 54.6476291\ttest: 66.7144906\tbest: 66.7144906 (1600)\ttotal: 12.8s\tremaining: 11.2s\n",
      "1700:\tlearn: 54.1090218\ttest: 66.6304871\tbest: 66.6170429 (1692)\ttotal: 13.5s\tremaining: 10.3s\n",
      "1800:\tlearn: 53.5579703\ttest: 66.4210123\tbest: 66.4210123 (1800)\ttotal: 14.3s\tremaining: 9.51s\n",
      "1900:\tlearn: 53.0893409\ttest: 66.3184280\tbest: 66.2937189 (1886)\ttotal: 15.1s\tremaining: 8.71s\n",
      "2000:\tlearn: 52.5562437\ttest: 66.2853635\tbest: 66.2440477 (1993)\ttotal: 15.8s\tremaining: 7.88s\n",
      "2100:\tlearn: 52.0523539\ttest: 66.1851126\tbest: 66.1851126 (2100)\ttotal: 16.6s\tremaining: 7.1s\n",
      "2200:\tlearn: 51.6170582\ttest: 66.1031237\tbest: 66.0967081 (2159)\ttotal: 17.7s\tremaining: 6.41s\n",
      "2300:\tlearn: 51.1709939\ttest: 65.9163097\tbest: 65.9136067 (2292)\ttotal: 18.8s\tremaining: 5.71s\n",
      "2400:\tlearn: 50.7703070\ttest: 65.8789449\tbest: 65.8345277 (2371)\ttotal: 20s\tremaining: 4.98s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 65.83452766\n",
      "bestIteration = 2371\n",
      "\n",
      "Shrink model to first 2372 iterations.\n",
      "0:\tlearn: 97.0193351\ttest: 99.0342314\tbest: 99.0342314 (0)\ttotal: 4.51ms\tremaining: 13.5s\n",
      "100:\tlearn: 66.7769885\ttest: 67.4528902\tbest: 67.4528902 (100)\ttotal: 892ms\tremaining: 25.6s\n",
      "200:\tlearn: 54.4948338\ttest: 56.7144132\tbest: 56.7144132 (200)\ttotal: 2.09s\tremaining: 29.1s\n",
      "300:\tlearn: 50.5678380\ttest: 53.6281011\tbest: 53.6200010 (298)\ttotal: 3.16s\tremaining: 28.3s\n",
      "400:\tlearn: 48.1062945\ttest: 51.8017260\tbest: 51.7840613 (399)\ttotal: 4.07s\tremaining: 26.4s\n",
      "500:\tlearn: 46.4533421\ttest: 51.0553413\tbest: 51.0488682 (499)\ttotal: 4.98s\tremaining: 24.8s\n",
      "600:\tlearn: 45.3052557\ttest: 50.7499074\tbest: 50.7341516 (589)\ttotal: 5.89s\tremaining: 23.5s\n",
      "700:\tlearn: 44.1275680\ttest: 50.0022173\tbest: 49.9924110 (698)\ttotal: 6.64s\tremaining: 21.8s\n",
      "800:\tlearn: 43.2657673\ttest: 49.6782993\tbest: 49.6782993 (800)\ttotal: 7.99s\tremaining: 21.9s\n",
      "900:\tlearn: 42.4985462\ttest: 49.4666134\tbest: 49.4666134 (900)\ttotal: 8.93s\tremaining: 20.8s\n",
      "1000:\tlearn: 41.8242181\ttest: 49.2526673\tbest: 49.2525491 (999)\ttotal: 9.81s\tremaining: 19.6s\n",
      "1100:\tlearn: 41.2971508\ttest: 49.0487045\tbest: 49.0463714 (1099)\ttotal: 10.6s\tremaining: 18.3s\n",
      "1200:\tlearn: 40.8143125\ttest: 48.7974726\tbest: 48.7925930 (1191)\ttotal: 11.5s\tremaining: 17.2s\n",
      "1300:\tlearn: 40.3550732\ttest: 48.6017265\tbest: 48.6014479 (1299)\ttotal: 12.2s\tremaining: 16s\n",
      "1400:\tlearn: 39.8972121\ttest: 48.5158152\tbest: 48.5091167 (1397)\ttotal: 13.3s\tremaining: 15.1s\n",
      "1500:\tlearn: 39.4648661\ttest: 48.3879388\tbest: 48.3690912 (1478)\ttotal: 14.7s\tremaining: 14.7s\n",
      "1600:\tlearn: 39.0935835\ttest: 48.2824161\tbest: 48.2775745 (1598)\ttotal: 16.5s\tremaining: 14.5s\n",
      "1700:\tlearn: 38.7711844\ttest: 48.2658601\tbest: 48.2633442 (1618)\ttotal: 17.7s\tremaining: 13.5s\n",
      "1800:\tlearn: 38.4200739\ttest: 48.2047710\tbest: 48.2046621 (1799)\ttotal: 18.6s\tremaining: 12.4s\n",
      "1900:\tlearn: 38.0767509\ttest: 48.1666664\tbest: 48.1365146 (1845)\ttotal: 19.7s\tremaining: 11.4s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 48.13651462\n",
      "bestIteration = 1845\n",
      "\n",
      "Shrink model to first 1846 iterations.\n",
      "MAE_LAUNCH : 65.8345286555789\n",
      "MAE_DINNER : 48.1365156233403\n",
      "TOTAL SCORE : 56.9855221394596\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reg_launch, reg_dinner = train_catboost(train_df, \n",
    "                                        test_df,\n",
    "                                        depth=2, \n",
    "                                        verbose=100,\n",
    "                                        k=0, \n",
    "                                        test_size=0.2,\n",
    "                                        seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, y, sample = processing(text='embedding', \n",
    "                                          DIM=2,\n",
    "                                          verbose=0,\n",
    "                                          min_count=0,\n",
    "                                          window_size=3,\n",
    "                                          min_ngram=2,\n",
    "                                          max_ngram=3,   \n",
    "                                          sum_reduction=False,\n",
    "                                          use_tok=False,\n",
    "                                          sep_date=True,\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>요일</th>\n",
       "      <th>본사정원수</th>\n",
       "      <th>본사휴가자수</th>\n",
       "      <th>본사출장자수</th>\n",
       "      <th>본사시간외근무명령서승인건수</th>\n",
       "      <th>현본사소속재택근무자수</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>breakfast_0</th>\n",
       "      <th>breakfast_1</th>\n",
       "      <th>launch_0</th>\n",
       "      <th>launch_1</th>\n",
       "      <th>dinner_0</th>\n",
       "      <th>dinner_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022481</td>\n",
       "      <td>0.323442</td>\n",
       "      <td>0.227969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.328111</td>\n",
       "      <td>0.924677</td>\n",
       "      <td>0.958274</td>\n",
       "      <td>0.211348</td>\n",
       "      <td>-0.333639</td>\n",
       "      <td>0.914947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022481</td>\n",
       "      <td>0.391691</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.301556</td>\n",
       "      <td>0.938399</td>\n",
       "      <td>0.951181</td>\n",
       "      <td>0.260686</td>\n",
       "      <td>-0.529107</td>\n",
       "      <td>0.735462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027477</td>\n",
       "      <td>0.412463</td>\n",
       "      <td>0.106322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.307250</td>\n",
       "      <td>0.935701</td>\n",
       "      <td>0.468310</td>\n",
       "      <td>0.820731</td>\n",
       "      <td>-0.292870</td>\n",
       "      <td>0.923697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067444</td>\n",
       "      <td>0.531157</td>\n",
       "      <td>0.340038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.268320</td>\n",
       "      <td>0.943259</td>\n",
       "      <td>0.957419</td>\n",
       "      <td>0.215146</td>\n",
       "      <td>-0.970038</td>\n",
       "      <td>0.109891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212323</td>\n",
       "      <td>0.415430</td>\n",
       "      <td>0.032567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.318779</td>\n",
       "      <td>0.930272</td>\n",
       "      <td>0.933504</td>\n",
       "      <td>0.321258</td>\n",
       "      <td>-0.365625</td>\n",
       "      <td>0.894952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>2</td>\n",
       "      <td>0.542614</td>\n",
       "      <td>0.043297</td>\n",
       "      <td>0.465875</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.733583</td>\n",
       "      <td>0.304527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.341600</td>\n",
       "      <td>0.835125</td>\n",
       "      <td>0.490622</td>\n",
       "      <td>0.784972</td>\n",
       "      <td>-0.913245</td>\n",
       "      <td>0.334217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>1</td>\n",
       "      <td>0.542614</td>\n",
       "      <td>0.057452</td>\n",
       "      <td>0.563798</td>\n",
       "      <td>0.442529</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.399177</td>\n",
       "      <td>0.063668</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0.323341</td>\n",
       "      <td>0.859361</td>\n",
       "      <td>0.807818</td>\n",
       "      <td>0.422196</td>\n",
       "      <td>-0.264632</td>\n",
       "      <td>0.919909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>0</td>\n",
       "      <td>0.542614</td>\n",
       "      <td>0.193172</td>\n",
       "      <td>0.614243</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.568480</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0.212831</td>\n",
       "      <td>0.892905</td>\n",
       "      <td>0.368154</td>\n",
       "      <td>0.852467</td>\n",
       "      <td>-0.455512</td>\n",
       "      <td>0.869566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>3</td>\n",
       "      <td>0.542614</td>\n",
       "      <td>0.069942</td>\n",
       "      <td>0.332344</td>\n",
       "      <td>0.590038</td>\n",
       "      <td>0.613508</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.297104</td>\n",
       "      <td>0.859851</td>\n",
       "      <td>0.764566</td>\n",
       "      <td>0.492922</td>\n",
       "      <td>-0.481827</td>\n",
       "      <td>0.833512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>4</td>\n",
       "      <td>0.542614</td>\n",
       "      <td>0.038301</td>\n",
       "      <td>0.421365</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.679174</td>\n",
       "      <td>0.415638</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0.067066</td>\n",
       "      <td>0.899020</td>\n",
       "      <td>0.562601</td>\n",
       "      <td>0.729004</td>\n",
       "      <td>-0.938691</td>\n",
       "      <td>0.243569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1205 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      요일     본사정원수    본사휴가자수    본사출장자수  본사시간외근무명령서승인건수  현본사소속재택근무자수      temp  \\\n",
       "0      3  0.000000  0.022481  0.323442        0.227969     0.000000  0.183128   \n",
       "1      4  0.000000  0.022481  0.391691        0.305556     0.000000  0.197531   \n",
       "2      2  0.000000  0.027477  0.412463        0.106322     0.000000  0.257202   \n",
       "3      1  0.000000  0.067444  0.531157        0.340038     0.000000  0.292181   \n",
       "4      0  0.000000  0.212323  0.415430        0.032567     0.000000  0.261317   \n",
       "...   ..       ...       ...       ...             ...          ...       ...   \n",
       "1200   2  0.542614  0.043297  0.465875        0.003831     0.733583  0.304527   \n",
       "1201   1  0.542614  0.057452  0.563798        0.442529     0.658537  0.399177   \n",
       "1202   0  0.542614  0.193172  0.614243        0.000958     0.568480  0.419753   \n",
       "1203   3  0.542614  0.069942  0.332344        0.590038     0.613508  0.469136   \n",
       "1204   4  0.542614  0.038301  0.421365        0.527778     0.679174  0.415638   \n",
       "\n",
       "          rain  month  day  week  breakfast_0  breakfast_1  launch_0  \\\n",
       "0     0.000000      2    1     0    -0.328111     0.924677  0.958274   \n",
       "1     0.000000      2    2     0    -0.301556     0.938399  0.951181   \n",
       "2     0.000000      2    3     0    -0.307250     0.935701  0.468310   \n",
       "3     0.000000      2    4     0    -0.268320     0.943259  0.957419   \n",
       "4     0.000000      2    5     0    -0.318779     0.930272  0.933504   \n",
       "...        ...    ...  ...   ...          ...          ...       ...   \n",
       "1200  0.000000      1   20     2     0.341600     0.835125  0.490622   \n",
       "1201  0.063668      1   21     3     0.323341     0.859361  0.807818   \n",
       "1202  0.000692      1   22     3     0.212831     0.892905  0.368154   \n",
       "1203  0.000000      1   25     3     0.297104     0.859851  0.764566   \n",
       "1204  0.011765      1   26     3     0.067066     0.899020  0.562601   \n",
       "\n",
       "      launch_1  dinner_0  dinner_1  \n",
       "0     0.211348 -0.333639  0.914947  \n",
       "1     0.260686 -0.529107  0.735462  \n",
       "2     0.820731 -0.292870  0.923697  \n",
       "3     0.215146 -0.970038  0.109891  \n",
       "4     0.321258 -0.365625  0.894952  \n",
       "...        ...       ...       ...  \n",
       "1200  0.784972 -0.913245  0.334217  \n",
       "1201  0.422196 -0.264632  0.919909  \n",
       "1202  0.852467 -0.455512  0.869566  \n",
       "1203  0.492922 -0.481827  0.833512  \n",
       "1204  0.729004 -0.938691  0.243569  \n",
       "\n",
       "[1205 rows x 17 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>요일</th>\n",
       "      <th>본사정원수</th>\n",
       "      <th>본사휴가자수</th>\n",
       "      <th>본사출장자수</th>\n",
       "      <th>본사시간외근무명령서승인건수</th>\n",
       "      <th>현본사소속재택근무자수</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>breakfast_0</th>\n",
       "      <th>breakfast_1</th>\n",
       "      <th>launch_0</th>\n",
       "      <th>launch_1</th>\n",
       "      <th>dinner_0</th>\n",
       "      <th>dinner_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022481</td>\n",
       "      <td>0.323442</td>\n",
       "      <td>0.227969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.384382</td>\n",
       "      <td>0.899315</td>\n",
       "      <td>0.963856</td>\n",
       "      <td>0.185830</td>\n",
       "      <td>-0.341007</td>\n",
       "      <td>0.912270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022481</td>\n",
       "      <td>0.391691</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.357028</td>\n",
       "      <td>0.915522</td>\n",
       "      <td>0.957702</td>\n",
       "      <td>0.236133</td>\n",
       "      <td>-0.532368</td>\n",
       "      <td>0.733278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027477</td>\n",
       "      <td>0.412463</td>\n",
       "      <td>0.106322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.368673</td>\n",
       "      <td>0.909323</td>\n",
       "      <td>0.486355</td>\n",
       "      <td>0.809349</td>\n",
       "      <td>-0.299320</td>\n",
       "      <td>0.921431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067444</td>\n",
       "      <td>0.531157</td>\n",
       "      <td>0.340038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.328957</td>\n",
       "      <td>0.921337</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.190820</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>0.101644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212323</td>\n",
       "      <td>0.415430</td>\n",
       "      <td>0.032567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.377070</td>\n",
       "      <td>0.904571</td>\n",
       "      <td>0.942352</td>\n",
       "      <td>0.295522</td>\n",
       "      <td>-0.373294</td>\n",
       "      <td>0.891523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>2</td>\n",
       "      <td>0.542614</td>\n",
       "      <td>0.043297</td>\n",
       "      <td>0.465875</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.733583</td>\n",
       "      <td>0.304527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.306769</td>\n",
       "      <td>0.845391</td>\n",
       "      <td>0.508735</td>\n",
       "      <td>0.774032</td>\n",
       "      <td>-0.917556</td>\n",
       "      <td>0.323175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>1</td>\n",
       "      <td>0.542614</td>\n",
       "      <td>0.057452</td>\n",
       "      <td>0.563798</td>\n",
       "      <td>0.442529</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.399177</td>\n",
       "      <td>0.063668</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0.282533</td>\n",
       "      <td>0.871354</td>\n",
       "      <td>0.821642</td>\n",
       "      <td>0.394880</td>\n",
       "      <td>-0.271240</td>\n",
       "      <td>0.918021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>0</td>\n",
       "      <td>0.542614</td>\n",
       "      <td>0.193172</td>\n",
       "      <td>0.614243</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.568480</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0.171729</td>\n",
       "      <td>0.899214</td>\n",
       "      <td>0.387554</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>-0.448166</td>\n",
       "      <td>0.873202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>3</td>\n",
       "      <td>0.542614</td>\n",
       "      <td>0.069942</td>\n",
       "      <td>0.332344</td>\n",
       "      <td>0.590038</td>\n",
       "      <td>0.613508</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.257112</td>\n",
       "      <td>0.868527</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.463389</td>\n",
       "      <td>-0.489620</td>\n",
       "      <td>0.827982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>4</td>\n",
       "      <td>0.542614</td>\n",
       "      <td>0.038301</td>\n",
       "      <td>0.421365</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.679174</td>\n",
       "      <td>0.415638</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0.019877</td>\n",
       "      <td>0.896897</td>\n",
       "      <td>0.582789</td>\n",
       "      <td>0.710595</td>\n",
       "      <td>-0.938942</td>\n",
       "      <td>0.242716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1205 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      요일     본사정원수    본사휴가자수    본사출장자수  본사시간외근무명령서승인건수  현본사소속재택근무자수      temp  \\\n",
       "0      3  0.000000  0.022481  0.323442        0.227969     0.000000  0.183128   \n",
       "1      4  0.000000  0.022481  0.391691        0.305556     0.000000  0.197531   \n",
       "2      2  0.000000  0.027477  0.412463        0.106322     0.000000  0.257202   \n",
       "3      1  0.000000  0.067444  0.531157        0.340038     0.000000  0.292181   \n",
       "4      0  0.000000  0.212323  0.415430        0.032567     0.000000  0.261317   \n",
       "...   ..       ...       ...       ...             ...          ...       ...   \n",
       "1200   2  0.542614  0.043297  0.465875        0.003831     0.733583  0.304527   \n",
       "1201   1  0.542614  0.057452  0.563798        0.442529     0.658537  0.399177   \n",
       "1202   0  0.542614  0.193172  0.614243        0.000958     0.568480  0.419753   \n",
       "1203   3  0.542614  0.069942  0.332344        0.590038     0.613508  0.469136   \n",
       "1204   4  0.542614  0.038301  0.421365        0.527778     0.679174  0.415638   \n",
       "\n",
       "          rain  month  day  week  breakfast_0  breakfast_1  launch_0  \\\n",
       "0     0.000000      2    1     0    -0.384382     0.899315  0.963856   \n",
       "1     0.000000      2    2     0    -0.357028     0.915522  0.957702   \n",
       "2     0.000000      2    3     0    -0.368673     0.909323  0.486355   \n",
       "3     0.000000      2    4     0    -0.328957     0.921337  0.962963   \n",
       "4     0.000000      2    5     0    -0.377070     0.904571  0.942352   \n",
       "...        ...    ...  ...   ...          ...          ...       ...   \n",
       "1200  0.000000      1   20     2     0.306769     0.845391  0.508735   \n",
       "1201  0.063668      1   21     3     0.282533     0.871354  0.821642   \n",
       "1202  0.000692      1   22     3     0.171729     0.899214  0.387554   \n",
       "1203  0.000000      1   25     3     0.257112     0.868527  0.782051   \n",
       "1204  0.011765      1   26     3     0.019877     0.896897  0.582789   \n",
       "\n",
       "      launch_1  dinner_0  dinner_1  \n",
       "0     0.185830 -0.341007  0.912270  \n",
       "1     0.236133 -0.532368  0.733278  \n",
       "2     0.809349 -0.299320  0.921431  \n",
       "3     0.190820 -0.970942  0.101644  \n",
       "4     0.295522 -0.373294  0.891523  \n",
       "...        ...       ...       ...  \n",
       "1200  0.774032 -0.917556  0.323175  \n",
       "1201  0.394880 -0.271240  0.918021  \n",
       "1202  0.843478 -0.448166  0.873202  \n",
       "1203  0.463389 -0.489620  0.827982  \n",
       "1204  0.710595 -0.938942  0.242716  \n",
       "\n",
       "[1205 rows x 17 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            일자          중식계         석식계\n",
      "0   2021-01-27  1059.124527  339.564667\n",
      "1   2021-01-28   975.859173  423.681958\n",
      "2   2021-01-29   700.566329  231.822373\n",
      "3   2021-02-01  1266.773316  465.702315\n",
      "4   2021-02-02  1045.126225  408.930388\n",
      "5   2021-02-03   977.272879  350.067663\n",
      "6   2021-02-04   971.669293  386.524374\n",
      "7   2021-02-05   705.797848  282.220481\n",
      "8   2021-02-08  1205.932265  523.682720\n",
      "9   2021-02-09  1096.225787  456.717027\n",
      "10  2021-02-10   865.119962  265.356322\n",
      "11  2021-02-15  1313.701883  624.725493\n",
      "12  2021-02-16  1116.281739  530.168552\n",
      "13  2021-02-17  1038.450521  334.889811\n",
      "14  2021-02-18   854.868356  416.699744\n",
      "15  2021-02-19   695.631073  303.494322\n",
      "16  2021-02-22  1229.828118  532.592874\n",
      "17  2021-02-23  1062.149589  534.693198\n",
      "18  2021-02-24   896.656916  343.654939\n",
      "19  2021-02-25   875.596015  400.567985\n",
      "20  2021-02-26   630.739475  211.876763\n",
      "21  2021-03-02  1133.777522  560.328366\n",
      "22  2021-03-03  1017.979485  362.290720\n",
      "23  2021-03-04   890.260112  461.063305\n",
      "24  2021-03-05   707.069360  295.358109\n",
      "25  2021-03-08  1249.828863  618.947664\n",
      "26  2021-03-09  1095.515938  593.783859\n",
      "27  2021-03-10  1023.548986  309.067174\n",
      "28  2021-03-11   927.350800  428.546524\n",
      "29  2021-03-12   734.739182  257.050246\n",
      "30  2021-03-15  1265.820414  600.379626\n",
      "31  2021-03-16  1055.828307  480.611204\n",
      "32  2021-03-17  1028.410338  319.415634\n",
      "33  2021-03-18   914.796201  418.008137\n",
      "34  2021-03-19   681.203722  242.780849\n",
      "35  2021-03-22  1287.246698  551.196211\n",
      "36  2021-03-23   994.654982  518.610941\n",
      "37  2021-03-24   928.527889  320.306650\n",
      "38  2021-03-25   840.971404  376.450543\n",
      "39  2021-03-26   661.382232  245.055221\n",
      "40  2021-03-29  1195.115483  548.812209\n",
      "41  2021-03-30  1044.538502  499.570940\n",
      "42  2021-03-31   972.432731  337.560978\n",
      "43  2021-04-01   831.473175  375.995459\n",
      "44  2021-04-02   666.989360  243.114541\n",
      "45  2021-04-05  1244.594265  523.069423\n",
      "46  2021-04-06  1042.305415  532.872966\n",
      "47  2021-04-07  1007.171555  354.719372\n",
      "48  2021-04-08   909.172207  373.855215\n",
      "49  2021-04-09   647.172747  185.292577\n"
     ]
    }
   ],
   "source": [
    "save_submission(reg_launch, reg_dinner, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
